{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dl framwork - tensorflow, keras a backend \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from IPython.display import display\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose input video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter video name: camera5.mp4\n"
     ]
    }
   ],
   "source": [
    "video=input('Enter video name: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the identified person face of starting time: 9\n"
     ]
    }
   ],
   "source": [
    "start_time=int(input('Enter the identified person face of starting time: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the identified person face of Ending time: 23\n"
     ]
    }
   ],
   "source": [
    "ending_time=int(input('Enter the identified person face of Ending time: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --trusted-host pypi.python.org moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "#from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "ffmpeg_extract_subclip(video,start_time,ending_time,targetname=\"test1.mp4\")\n",
    "#VideoFileClip(video,start_time,ending_time,targetname=\"test1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "cam = cv2.VideoCapture('test1.mp4')\n",
    "cam.set(3, 640) # set video width\n",
    "cam.set(4, 480) # set video height\n",
    "\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_defaul.xml')\n",
    "\n",
    "# For each person, enter one numeric face id\n",
    "face_id = input('\\n enter user id end press <return> ==>  ')\n",
    "\n",
    "print(\"\\n [INFO] Initializing face capture. Look the camera and wait ...\")\n",
    "# Initialize individual sampling face count\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, img = cam.read()\n",
    "    # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"dataset/User.\" + str(face_id) + '.' + str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >=200: # Take 30 face sample and stop video\n",
    "         break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# Dl framwork - tensorflow, keras a backend \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from IPython.display import display\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_train = 'dataSet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(item_dir, n=6):\n",
    "    all_item_dir = os.listdir(item_dir)\n",
    "    item_files = [os.path.join(item_dir, file) for file in all_item_dir][:n]\n",
    "    \n",
    "    plt.figure(figsize=(35, 10))\n",
    "    for idx, img_path in enumerate(item_files):\n",
    "        plt.subplot(2, n, idx+1)\n",
    "        img = plt.imread(img_path)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Images_details_Print_data(data, path):\n",
    "    print(\" ====== Images in: \", path)    \n",
    "    for k, v in data.items():\n",
    "        print(\"%s:\\t%s\" % (k, v))\n",
    "\n",
    "def Images_details(path):\n",
    "    files = [f for f in glob.glob(path + \"**/*.*\", recursive=True)]\n",
    "    data = {}\n",
    "    data['images_count'] = len(files)\n",
    "    data['min_width'] = 10**100  # No image will be bigger than that\n",
    "    data['max_width'] = 0\n",
    "    data['min_height'] = 10**100  # No image will be bigger than that\n",
    "    data['max_height'] = 0\n",
    "\n",
    "\n",
    "    for f in files:\n",
    "        im = Image.open(f)\n",
    "        width, height = im.size\n",
    "        data['min_width'] = min(width, data['min_width'])\n",
    "        data['max_width'] = max(width, data['max_height'])\n",
    "        data['min_height'] = min(height, data['min_height'])\n",
    "        data['max_height'] = max(height, data['max_height'])\n",
    "\n",
    "    Images_details_Print_data(data, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Training datasets:\")\n",
    "print(\"\")\n",
    "Images_details(dir_name_train)\n",
    "print(\"\")\n",
    "plot_images(dir_name_train, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
